/**
 * YOLO Keypoint Export Utilities
 *
 * Exports annotations with follicle origin data (entry point + direction)
 * in YOLO keypoint format for training YOLO11-pose models.
 *
 * YOLO Keypoint Format (for cropped images):
 * <class> 0.5 0.5 1.0 1.0 <kp1_x> <kp1_y> <kp1_vis> <kp2_x> <kp2_y> <kp2_vis>
 *
 * Where:
 * - Class is always 0 (follicle)
 * - Bounding box is 0.5 0.5 1.0 1.0 (full crop = center at 0.5, size 1.0)
 * - kp1 = origin point (where follicle enters skin)
 * - kp2 = direction endpoint (indicates growth direction)
 * - visibility = 2 (labeled and visible)
 */

import {
  RectangleAnnotation,
  ProjectImage,
  Follicle,
  isRectangle,
} from '../types';

/**
 * Keypoint annotation data for a single follicle
 */
export interface KeypointAnnotation {
  /** Origin point normalized to crop (0-1) */
  originX: number;
  originY: number;
  /** Direction endpoint normalized to crop (0-1) */
  directionEndX: number;
  directionEndY: number;
  /** Original annotation for reference */
  annotation: RectangleAnnotation;
  /** Source image info */
  imageId: string;
}

/**
 * Configuration for keypoint dataset export
 */
export interface KeypointExportConfig {
  /** Train/validation split ratio (0-1, default 0.8 = 80% train) */
  trainSplit: number;
  /** Whether to shuffle before splitting (default true) */
  shuffle: boolean;
  /** Padding around crop as percentage of bbox size (default 0.1 = 10%) */
  cropPadding: number;
  /** Minimum crop size in pixels (default 32) */
  minCropSize: number;
}

export const DEFAULT_KEYPOINT_EXPORT_CONFIG: KeypointExportConfig = {
  trainSplit: 0.8,
  shuffle: true,
  cropPadding: 0.1,
  minCropSize: 32,
};

/**
 * Transform a rectangle annotation with origin to keypoint annotation data.
 *
 * Converts image coordinates to normalized crop coordinates (0-1).
 *
 * @param annotation Rectangle annotation with origin data
 * @param cropPadding Padding around crop as percentage of bbox size
 * @returns KeypointAnnotation or null if no origin data
 */
export function transformToKeypointAnnotation(
  annotation: RectangleAnnotation,
  cropPadding: number = 0.1
): KeypointAnnotation | null {
  if (!annotation.origin) {
    return null;
  }

  const { x, y, width, height, origin } = annotation;

  // Calculate padded crop bounds
  const padX = width * cropPadding;
  const padY = height * cropPadding;
  const cropX = x - padX;
  const cropY = y - padY;
  const cropWidth = width + padX * 2;
  const cropHeight = height + padY * 2;

  // Transform origin point from image coords to normalized crop coords
  const originX = (origin.originPoint.x - cropX) / cropWidth;
  const originY = (origin.originPoint.y - cropY) / cropHeight;

  // Calculate direction endpoint from angle and length
  const endX = origin.originPoint.x + Math.cos(origin.directionAngle) * origin.directionLength;
  const endY = origin.originPoint.y + Math.sin(origin.directionAngle) * origin.directionLength;

  // Transform direction endpoint to normalized crop coords
  const directionEndX = (endX - cropX) / cropWidth;
  const directionEndY = (endY - cropY) / cropHeight;

  return {
    originX,
    originY,
    directionEndX,
    directionEndY,
    annotation,
    imageId: annotation.imageId,
  };
}

/**
 * Generate YOLO keypoint label line for an annotation.
 *
 * Format: <class> <x_center> <y_center> <width> <height> <kp1_x> <kp1_y> <kp1_vis> <kp2_x> <kp2_y> <kp2_vis>
 *
 * For cropped images, bbox is always centered and full-size: 0.5 0.5 1.0 1.0
 *
 * @param keypoint Keypoint annotation data
 * @returns YOLO format label string
 */
export function generateKeypointLabel(keypoint: KeypointAnnotation): string {
  const classId = 0; // Single class: follicle
  const visibility = 2; // Labeled and visible

  // For cropped images, bbox covers entire crop
  const bboxX = 0.5;
  const bboxY = 0.5;
  const bboxW = 1.0;
  const bboxH = 1.0;

  // Clamp keypoint coordinates to valid range (0-1)
  const kp1X = Math.max(0, Math.min(1, keypoint.originX));
  const kp1Y = Math.max(0, Math.min(1, keypoint.originY));
  const kp2X = Math.max(0, Math.min(1, keypoint.directionEndX));
  const kp2Y = Math.max(0, Math.min(1, keypoint.directionEndY));

  return [
    classId,
    bboxX.toFixed(6),
    bboxY.toFixed(6),
    bboxW.toFixed(6),
    bboxH.toFixed(6),
    kp1X.toFixed(6),
    kp1Y.toFixed(6),
    visibility,
    kp2X.toFixed(6),
    kp2Y.toFixed(6),
    visibility,
  ].join(' ');
}

/**
 * Generate data.yaml config for YOLO keypoint training.
 */
export function generateKeypointDataYaml(): string {
  return `# YOLO Keypoint Dataset Configuration
# Generated by Follicle Labeller
# For YOLO11-pose training

path: .
train: images/train
val: images/val

# Classes
nc: 1
names:
  0: follicle

# Keypoint configuration
# 2 keypoints: origin point (entry into skin) and direction endpoint
# 3 values per keypoint: x, y, visibility
kpt_shape: [2, 3]

# No horizontal flip - direction matters
flip_idx: []
`;
}

/**
 * Crop an image region with padding.
 *
 * @param imageData Source image ArrayBuffer
 * @param annotation Rectangle annotation defining the crop area
 * @param padding Padding as percentage of bbox size
 * @param minSize Minimum crop size
 * @returns Promise resolving to cropped image blob
 */
export async function cropAnnotationRegion(
  imageBitmap: ImageBitmap,
  annotation: RectangleAnnotation,
  padding: number = 0.1,
  minSize: number = 32
): Promise<Blob> {
  const { x, y, width, height } = annotation;
  const imgWidth = imageBitmap.width;
  const imgHeight = imageBitmap.height;

  // Calculate padded crop bounds
  const padX = width * padding;
  const padY = height * padding;

  let cropX = Math.max(0, Math.floor(x - padX));
  let cropY = Math.max(0, Math.floor(y - padY));
  let cropWidth = Math.min(imgWidth - cropX, Math.ceil(width + padX * 2));
  let cropHeight = Math.min(imgHeight - cropY, Math.ceil(height + padY * 2));

  // Ensure minimum size
  if (cropWidth < minSize) {
    const diff = minSize - cropWidth;
    cropX = Math.max(0, cropX - diff / 2);
    cropWidth = Math.min(imgWidth - cropX, minSize);
  }
  if (cropHeight < minSize) {
    const diff = minSize - cropHeight;
    cropY = Math.max(0, cropY - diff / 2);
    cropHeight = Math.min(imgHeight - cropY, minSize);
  }

  // Create canvas and draw cropped region
  const canvas = document.createElement('canvas');
  canvas.width = cropWidth;
  canvas.height = cropHeight;
  const ctx = canvas.getContext('2d');

  if (!ctx) {
    throw new Error('Failed to get canvas context');
  }

  ctx.drawImage(
    imageBitmap,
    cropX,
    cropY,
    cropWidth,
    cropHeight,
    0,
    0,
    cropWidth,
    cropHeight
  );

  // Convert to blob
  return new Promise<Blob>((resolve, reject) => {
    canvas.toBlob(
      (blob) => {
        if (blob) {
          resolve(blob);
        } else {
          reject(new Error('Failed to create blob from canvas'));
        }
      },
      'image/jpeg',
      0.95
    );
  });
}

/**
 * Shuffle array in place using Fisher-Yates algorithm.
 */
function shuffleArray<T>(array: T[]): T[] {
  const result = [...array];
  for (let i = result.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [result[i], result[j]] = [result[j], result[i]];
  }
  return result;
}

/**
 * Export result containing all files for the YOLO keypoint dataset.
 */
export interface KeypointDatasetFile {
  /** Path within the ZIP (e.g., "images/train/img_001.jpg") */
  path: string;
  /** File content (blob for images, string for text files) */
  content: Blob | string;
}

/**
 * Statistics about the exported dataset.
 */
export interface KeypointDatasetStats {
  totalAnnotations: number;
  annotationsWithOrigin: number;
  trainCount: number;
  valCount: number;
  skippedNoOrigin: number;
}

/**
 * Export all annotations with origin data as a YOLO keypoint dataset.
 *
 * Creates a dataset structure:
 * - data.yaml (config file)
 * - images/train/*.jpg (training images - cropped follicles)
 * - images/val/*.jpg (validation images)
 * - labels/train/*.txt (training labels)
 * - labels/val/*.txt (validation labels)
 *
 * @param images Map of project images
 * @param follicles All annotations
 * @param config Export configuration
 * @returns Object with files array and statistics
 */
export async function exportYOLOKeypointDataset(
  images: Map<string, ProjectImage>,
  follicles: Follicle[],
  config: KeypointExportConfig = DEFAULT_KEYPOINT_EXPORT_CONFIG
): Promise<{ files: KeypointDatasetFile[]; stats: KeypointDatasetStats }> {
  const files: KeypointDatasetFile[] = [];

  // Filter to rectangle annotations with origin data
  const rectanglesWithOrigin = follicles.filter(
    (f): f is RectangleAnnotation => isRectangle(f) && !!f.origin
  );

  const stats: KeypointDatasetStats = {
    totalAnnotations: follicles.length,
    annotationsWithOrigin: rectanglesWithOrigin.length,
    trainCount: 0,
    valCount: 0,
    skippedNoOrigin: follicles.length - rectanglesWithOrigin.length,
  };

  if (rectanglesWithOrigin.length === 0) {
    // Add empty data.yaml
    files.push({
      path: 'data.yaml',
      content: generateKeypointDataYaml(),
    });
    return { files, stats };
  }

  // Optionally shuffle
  let annotations = config.shuffle
    ? shuffleArray(rectanglesWithOrigin)
    : rectanglesWithOrigin;

  // Split into train/val
  const splitIndex = Math.floor(annotations.length * config.trainSplit);
  const trainAnnotations = annotations.slice(0, splitIndex);
  const valAnnotations = annotations.slice(splitIndex);

  stats.trainCount = trainAnnotations.length;
  stats.valCount = valAnnotations.length;

  // Add data.yaml
  files.push({
    path: 'data.yaml',
    content: generateKeypointDataYaml(),
  });

  // Process train set
  let index = 0;
  for (const annotation of trainAnnotations) {
    const image = images.get(annotation.imageId);
    if (!image) continue;

    const keypoint = transformToKeypointAnnotation(annotation, config.cropPadding);
    if (!keypoint) continue;

    const baseName = `follicle_${String(index).padStart(5, '0')}`;

    // Crop image region
    const cropBlob = await cropAnnotationRegion(
      image.imageBitmap,
      annotation,
      config.cropPadding,
      config.minCropSize
    );

    files.push({
      path: `images/train/${baseName}.jpg`,
      content: cropBlob,
    });

    files.push({
      path: `labels/train/${baseName}.txt`,
      content: generateKeypointLabel(keypoint),
    });

    index++;
  }

  // Process val set
  for (const annotation of valAnnotations) {
    const image = images.get(annotation.imageId);
    if (!image) continue;

    const keypoint = transformToKeypointAnnotation(annotation, config.cropPadding);
    if (!keypoint) continue;

    const baseName = `follicle_${String(index).padStart(5, '0')}`;

    // Crop image region
    const cropBlob = await cropAnnotationRegion(
      image.imageBitmap,
      annotation,
      config.cropPadding,
      config.minCropSize
    );

    files.push({
      path: `images/val/${baseName}.jpg`,
      content: cropBlob,
    });

    files.push({
      path: `labels/val/${baseName}.txt`,
      content: generateKeypointLabel(keypoint),
    });

    index++;
  }

  return { files, stats };
}

/**
 * Create a ZIP file from the keypoint dataset files.
 *
 * @param files Dataset files from exportYOLOKeypointDataset
 * @returns Promise resolving to ZIP blob
 */
export async function createKeypointDatasetZip(
  files: KeypointDatasetFile[]
): Promise<Blob> {
  const JSZip = (await import('jszip')).default;
  const zip = new JSZip();

  for (const file of files) {
    if (typeof file.content === 'string') {
      zip.file(file.path, file.content);
    } else {
      zip.file(file.path, file.content);
    }
  }

  return zip.generateAsync({
    type: 'blob',
    compression: 'DEFLATE',
    compressionOptions: { level: 6 },
  });
}
